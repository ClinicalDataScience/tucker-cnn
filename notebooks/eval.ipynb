{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from monai.transforms import (  LoadImaged,\n",
    "                                EnsureChannelFirstd,\n",
    "                                Compose,\n",
    "                                ScaleIntensityRanged,\n",
    "                                CropForegroundd,\n",
    "                                Orientationd,\n",
    "                                Spacingd,\n",
    "                                Spacing,\n",
    "                                NormalizeIntensity,)\n",
    "\n",
    "from monai.transforms.compose import MapTransform\n",
    "from nnunetv2.inference.predict_from_raw_data import load_what_we_need\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.inferers import sliding_window_inference"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:27:45.647273198Z",
     "start_time": "2024-02-02T16:27:41.432085430Z"
    }
   },
   "id": "f2d1f36060c5b7a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Predicting...\n",
    "(CUDA) Elapsed time:  402.07ms\n",
    "(CUDA) Elapsed time:   66.62ms\n",
    "(CUDA) Elapsed time:   66.05ms\n",
    "(CUDA) Elapsed time:   65.52ms\n",
    "(CUDA) Elapsed time:   63.91ms\n",
    "(CUDA) Elapsed time:   63.46ms\n",
    "(CUDA) Elapsed time:   63.56ms\n",
    "(CUDA) Elapsed time:   64.41ms\n",
    "  Predicted in 8.84s\n",
    "Resampling...\n",
    "Saving segmentations...\n",
    "100%|██████████| 117/117 [00:04<00:00, 23.76it/s]\n",
    "  Saved in 5.50s\n",
    "Execution took 64.79±1.18ms over 7 function calls.\n",
    "1 function call was ignored in this report due to warm up.\n",
    "Dice Score: 0.949\n",
    "\n",
    "Process finished with exit code 0\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3adaa4083762b449"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TS_ROOT = os.path.join(os.environ['HOME'], '.totalsegmentator/nnunet/results')\n",
    "patch_size = (1, 112, 112, 128)\n",
    "model_path = (\n",
    "    'Dataset297_TotalSegmentator_total_3mm_1559subj/'\n",
    "    'nnUNetTrainer_4000epochs_NoMirroring__nnUNetPlans__3d_fullres'\n",
    ")\n",
    "path = os.path.join(TS_ROOT, model_path)\n",
    "data_d = [{\"image\": \"/mnt/ssd/PycharmProjects/tucker-cnn/data/spleen/imagesTr/spleen_2.nii.gz\"}]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:27:45.707034139Z",
     "start_time": "2024-02-02T16:27:45.647034900Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "mostly_useless_stuff = load_what_we_need(\n",
    "        model_training_output_dir=path,\n",
    "        use_folds=[0],\n",
    "        checkpoint_name='checkpoint_final.pth',\n",
    "    )\n",
    "network = mostly_useless_stuff[-2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:27:47.418145287Z",
     "start_time": "2024-02-02T16:27:45.650922366Z"
    }
   },
   "id": "12df5513409a54ae"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class PreprocessNorm(MapTransform):\n",
    "    \"\"\"\n",
    "    This transform class takes NNUNet's preprocessing method for reference.\n",
    "    That code is in:\n",
    "    https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunet/preprocessing/preprocessing.py\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys,\n",
    "        clip_values,\n",
    "        normalize_values,\n",
    "    ) -> None:\n",
    "        super().__init__(keys)\n",
    "        self.keys = keys\n",
    "        self.low = clip_values[0]\n",
    "        self.high = clip_values[1]\n",
    "        self.mean = normalize_values[0]\n",
    "        self.std = normalize_values[1]\n",
    "        self.training = False\n",
    "        self.normalize_intensity = NormalizeIntensity(nonzero=True, channel_wise=True)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # load data\n",
    "        d = dict(data)\n",
    "        image = d[\"image\"]\n",
    "\n",
    "        # clip image for CT dataset\n",
    "        if self.low != 0 or self.high != 0:\n",
    "            image = torch.clamp(image, self.low, self.high)\n",
    "            image = (image - self.mean) / self.std\n",
    "        else:\n",
    "            image = self.normalize_intensity(image.copy())\n",
    "\n",
    "        d[\"image\"] = image\n",
    "        return d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:31:50.075107899Z",
     "start_time": "2024-02-02T16:31:50.064049647Z"
    }
   },
   "id": "9084efdb25324900"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "val_keys = [\"image\", \"label\"]\n",
    "val_mode = (\"bilinear\", \"nearest\")\n",
    "test_keys = [\"image\"]\n",
    "\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=test_keys),\n",
    "        EnsureChannelFirstd(keys=test_keys),\n",
    "        PreprocessNorm(\n",
    "            keys=test_keys,\n",
    "            clip_values=(-1004.0, 1588.0),\n",
    "            normalize_values=(-50.38697721419439, 503.39235619144),\n",
    "        ),\n",
    "        #CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        #Orientationd(keys=test_keys, axcodes=\"LAS\"),\n",
    "        Spacingd(keys=test_keys, pixdim=(3., 3., 3.), mode=(\"bilinear\")), #pixdim=(1.5, 1.5, 1.5)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:31:50.958877500Z",
     "start_time": "2024-02-02T16:31:50.942843898Z"
    }
   },
   "id": "92676a2ed563f9ee"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=data_d, transform=test_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T15:37:51.611882726Z",
     "start_time": "2024-02-02T15:37:51.606988210Z"
    }
   },
   "id": "b86ad79fcc76294"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "im = check_ds.__getitem__(0)[\"image\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T15:37:52.443040671Z",
     "start_time": "2024-02-02T15:37:51.611437909Z"
    }
   },
   "id": "959e385fbf7cecaf"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 512, 512, 90])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T15:37:53.234197615Z",
     "start_time": "2024-02-02T15:37:53.223403712Z"
    }
   },
   "id": "a4b3ffd6e8def2b9"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fa7d15157d0>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(im[0,:,:,60])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:27:10.560266060Z",
     "start_time": "2024-02-02T16:27:08.476267576Z"
    }
   },
   "id": "b7ae601725fe5b80"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:27:50.244990469Z",
     "start_time": "2024-02-02T16:27:50.239067874Z"
    }
   },
   "id": "5f2a0bc1a9940d2d"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "a = np.load(\"seg_pred.npy\")\n",
    "b = np.load(\"seg_true.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:28:53.099632426Z",
     "start_time": "2024-02-02T16:28:53.081519113Z"
    }
   },
   "id": "ea406f6b04ab94cc"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"softmax_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m aa \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \"softmax_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "aa = torch.softmax(torch.from_numpy(a), dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:28:53.999035791Z",
     "start_time": "2024-02-02T16:28:53.966658439Z"
    }
   },
   "id": "83a64bf049e7bcba"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43maa\u001B[49m\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mNameError\u001B[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "aa.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:28:47.075542990Z",
     "start_time": "2024-02-02T16:28:47.069825451Z"
    }
   },
   "id": "5458649243f0a1d7"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43maa\u001B[49m\u001B[38;5;241m.\u001B[39mmax()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "aa.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:28:47.972944594Z",
     "start_time": "2024-02-02T16:28:47.968019707Z"
    }
   },
   "id": "7db193fd1dd33c53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(a[0,:,:,60]>0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:28:47.973620225Z",
     "start_time": "2024-02-02T16:28:47.973289633Z"
    }
   },
   "id": "1613bdf9029787e2"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old shape: (90, 512, 512), new_shape: [150 136 136], old_spacing: [5.0, 0.7949219942092896, 0.7949219942092896], new_spacing: [3.0, 3.0, 3.0], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f281e6db4c0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n"
     ]
    }
   ],
   "source": [
    "from nnunetv2.preprocessing.preprocessors.default_preprocessor import DefaultPreprocessor\n",
    "plans_manager = mostly_useless_stuff[3]\n",
    "dataset_json_file = mostly_useless_stuff[4]\n",
    "pp = DefaultPreprocessor()\n",
    "data, _, properties = pp.run_case([\"/mnt/ssd/PycharmProjects/tucker-cnn/data/spleen/imagesTr/spleen_2.nii.gz\"], seg_file=None, plans_manager=plans_manager,\n",
    "                                      configuration_manager=plans_manager.get_configuration('3d_fullres'),\n",
    "                                      dataset_json=dataset_json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:27:57.281828621Z",
     "start_time": "2024-02-02T16:27:54.553471511Z"
    }
   },
   "id": "6ca1b5a95f8350de"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_755358/1157872989.py:2: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(data[0, 70, :,:])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:28:11.201985051Z",
     "start_time": "2024-02-02T16:28:11.176403363Z"
    }
   },
   "id": "499dca1fc8315f62"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def example_test_case_preprocessing():\n",
    "    # (paths to files may need adaptations)\n",
    "    plans_file = '/home/isensee/drives/gpu_data/nnUNet_preprocessed/Dataset219_AMOS2022_postChallenge_task2/nnUNetPlans.json'\n",
    "    dataset_json_file = '/home/isensee/drives/gpu_data/nnUNet_preprocessed/Dataset219_AMOS2022_postChallenge_task2/dataset.json'\n",
    "    input_images = ['/home/isensee/drives/e132-rohdaten/nnUNetv2/Dataset219_AMOS2022_postChallenge_task2/imagesTr/amos_0600_0000.nii.gz', ]  # if you only have one channel, you still need a list: ['case000_0000.nii.gz']\n",
    "\n",
    "    configuration = '3d_fullres'\n",
    "    pp = DefaultPreprocessor()\n",
    "\n",
    "    # _ because this position would be the segmentation if seg_file was not None (training case)\n",
    "    # even if you have the segmentation, don't put the file there! You should always evaluate in the original\n",
    "    # resolution. What comes out of the preprocessor might have been resampled to some other image resolution (as\n",
    "    # specified by plans)\n",
    "    plans_manager = PlansManager(plans_file)\n",
    "    data, _, properties = pp.run_case(input_images, seg_file=None, plans_manager=plans_manager,\n",
    "                                      configuration_manager=plans_manager.get_configuration(configuration),\n",
    "                                      dataset_json=dataset_json_file)\n",
    "\n",
    "    # voila. Now plug data into your prediction function of choice. We of course recommend nnU-Net's default (TODO)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e0947a1b63a2962"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
